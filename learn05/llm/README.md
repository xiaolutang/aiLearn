# æ™ºèƒ½æ•™å­¦åŠ©æ‰‹LLMç³»ç»Ÿ

## æ¦‚è¿°

æ™ºèƒ½æ•™å­¦åŠ©æ‰‹LLMç³»ç»Ÿæ˜¯ä¸€ä¸ªä¸“ä¸ºæ•™è‚²åœºæ™¯è®¾è®¡çš„å¤§è¯­è¨€æ¨¡å‹é›†æˆæ¡†æ¶ï¼Œæä¾›æ•™æåˆ†æã€å­¦æƒ…åˆ†æã€è¾…å¯¼æ–¹æ¡ˆç”Ÿæˆã€è¯¾å ‚AIåŠ©æ‰‹ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒå¤šç§å¤§æ¨¡å‹æä¾›å•†ï¼Œå…·å¤‡å®Œå–„çš„ä¸Šä¸‹æ–‡ç®¡ç†ã€æ€§èƒ½ä¼˜åŒ–å’Œç›‘æ§åŠŸèƒ½ã€‚

## æ ¸å¿ƒç‰¹æ€§

### ğŸ¤– æ™ºèƒ½ä½“ç³»ç»Ÿ
- **æ•™æåˆ†ææ™ºèƒ½ä½“**: è‡ªåŠ¨è§£ææ•™æå†…å®¹ï¼Œè¯†åˆ«çŸ¥è¯†ç‚¹ï¼Œè¯„ä¼°éš¾åº¦
- **å­¦æƒ…åˆ†ææ™ºèƒ½ä½“**: åŸºäºæˆç»©æ•°æ®ç”Ÿæˆä¸ªæ€§åŒ–å­¦æƒ…æŠ¥å‘Š
- **è¾…å¯¼æ–¹æ¡ˆæ™ºèƒ½ä½“**: æä¾›ä¸ªæ€§åŒ–å­¦ä¹ å»ºè®®å’Œç»ƒä¹ æ¨è
- **è¯¾å ‚AIåŠ©æ‰‹**: å®æ—¶å­¦æƒ…åˆ†æå’Œäº’åŠ¨å†…å®¹ç”Ÿæˆ

### ğŸ¯ æç¤ºè¯ç®¡ç†
- ä¸°å¯Œçš„æç¤ºè¯æ¨¡æ¿åº“
- åŠ¨æ€æ¨¡æ¿æ ¼å¼åŒ–
- æ¨¡æ¿ä½¿ç”¨ç»Ÿè®¡å’Œä¼˜åŒ–
- è‡ªå®šä¹‰æ¨¡æ¿æ”¯æŒ

### ğŸ’¬ ä¸Šä¸‹æ–‡ç®¡ç†
- å¤šè½®å¯¹è¯æ”¯æŒ
- ä¼šè¯çŠ¶æ€ä¿æŒ
- æ™ºèƒ½ä¸Šä¸‹æ–‡å‹ç¼©
- è®°å¿†å­˜å‚¨å’Œæ£€ç´¢

### âš¡ æ€§èƒ½ä¼˜åŒ–
- æ™ºèƒ½ç¼“å­˜æœºåˆ¶
- å¹¶å‘å¤„ç†æ”¯æŒ
- å®æ—¶æ€§èƒ½ç›‘æ§
- è‡ªåŠ¨ä¼˜åŒ–å»ºè®®

### ğŸ”Œ å¤šæ¨¡å‹æ”¯æŒ
- é˜¿é‡Œäº‘é€šä¹‰åƒé—®
- OpenAI GPTç³»åˆ—
- å…¶ä»–ä¸»æµå¤§æ¨¡å‹
- ç»Ÿä¸€çš„APIæ¥å£

## ç³»ç»Ÿæ¶æ„

```
æ™ºèƒ½æ•™å­¦åŠ©æ‰‹LLMç³»ç»Ÿ
â”œâ”€â”€ agents/                 # æ™ºèƒ½ä½“æ¨¡å—
â”‚   â”œâ”€â”€ base_agent.py      # æ™ºèƒ½ä½“åŸºç±»
â”‚   â”œâ”€â”€ teaching_analysis.py # æ•™æåˆ†ææ™ºèƒ½ä½“
â”‚   â”œâ”€â”€ learning_status.py   # å­¦æƒ…åˆ†ææ™ºèƒ½ä½“
â”‚   â”œâ”€â”€ tutoring_plan.py     # è¾…å¯¼æ–¹æ¡ˆæ™ºèƒ½ä½“
â”‚   â”œâ”€â”€ classroom_ai.py      # è¯¾å ‚AIåŠ©æ‰‹
â”‚   â””â”€â”€ agent_manager.py     # æ™ºèƒ½ä½“ç®¡ç†å™¨
â”œâ”€â”€ prompts/               # æç¤ºè¯ç®¡ç†
â”‚   â”œâ”€â”€ teaching_prompts.py # æ•™å­¦æç¤ºè¯
â”‚   â”œâ”€â”€ learning_prompts.py # å­¦æƒ…æç¤ºè¯
â”‚   â”œâ”€â”€ tutoring_prompts.py # è¾…å¯¼æç¤ºè¯
â”‚   â”œâ”€â”€ classroom_prompts.py # è¯¾å ‚æç¤ºè¯
â”‚   â””â”€â”€ prompt_manager.py   # æç¤ºè¯ç®¡ç†å™¨
â”œâ”€â”€ context/               # ä¸Šä¸‹æ–‡ç®¡ç†
â”‚   â”œâ”€â”€ context_manager.py # ä¸Šä¸‹æ–‡ç®¡ç†å™¨
â”‚   â”œâ”€â”€ session_manager.py # ä¼šè¯ç®¡ç†å™¨
â”‚   â”œâ”€â”€ memory_store.py    # è®°å¿†å­˜å‚¨
â”‚   â””â”€â”€ context_strategies.py # ä¸Šä¸‹æ–‡ç­–ç•¥
â”œâ”€â”€ optimization/          # æ€§èƒ½ä¼˜åŒ–
â”‚   â”œâ”€â”€ cache_manager.py   # ç¼“å­˜ç®¡ç†
â”‚   â”œâ”€â”€ concurrent_processor.py # å¹¶å‘å¤„ç†
â”‚   â”œâ”€â”€ performance_monitor.py # æ€§èƒ½ç›‘æ§
â”‚   â””â”€â”€ optimization_manager.py # ä¼˜åŒ–ç®¡ç†å™¨
â”œâ”€â”€ llm_client.py         # LLMå®¢æˆ·ç«¯
â”œâ”€â”€ config.py             # é…ç½®ç®¡ç†
â””â”€â”€ examples/             # ä½¿ç”¨ç¤ºä¾‹
    â””â”€â”€ usage_examples.py # å®Œæ•´ç¤ºä¾‹
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install openai dashscope psutil pandas numpy
```

### 2. é…ç½®APIå¯†é’¥

```python
from service.llm.llm_client import LLMClient, LLMConfig

# é…ç½®é€šä¹‰åƒé—®
config = LLMConfig(
    provider="tongyi",
    api_key="your-dashscope-api-key",
    model="qwen-plus"
)

# æˆ–é…ç½®OpenAI
config = LLMConfig(
    provider="openai",
    api_key="your-openai-api-key",
    model="gpt-3.5-turbo"
)

llm_client = LLMClient(config)
```

### 3. åŸºæœ¬ä½¿ç”¨

#### æ•™æåˆ†æ

```python
from service.llm.agents import TeachingAnalysisAgent

# åˆ›å»ºæ•™æåˆ†ææ™ºèƒ½ä½“
teaching_agent = TeachingAnalysisAgent(llm_client)

# åˆ†ææ•™æ
material = {
    "subject": "æ•°å­¦",
    "grade": "é«˜ä¸€",
    "content": "å‡½æ•°çš„æ¦‚å¿µå’Œæ€§è´¨"
}

result = await teaching_agent.analyze_material(material)
print(result)
```

#### å­¦æƒ…åˆ†æ

```python
from service.llm.agents import LearningStatusAgent

# åˆ›å»ºå­¦æƒ…åˆ†ææ™ºèƒ½ä½“
learning_agent = LearningStatusAgent(llm_client)

# åˆ†æå­¦æƒ…
student_data = {
    "student_id": "S001",
    "subject_scores": {
        "æ•°å­¦": [85, 78, 92, 88, 90]
    }
}

result = await learning_agent.analyze_learning_status(student_data)
print(result)
```

#### è¾…å¯¼æ–¹æ¡ˆç”Ÿæˆ

```python
from service.llm.agents import TutoringPlanAgent

# åˆ›å»ºè¾…å¯¼æ–¹æ¡ˆæ™ºèƒ½ä½“
tutoring_agent = TutoringPlanAgent(llm_client)

# ç”Ÿæˆè¾…å¯¼æ–¹æ¡ˆ
request = {
    "student_info": {"grade": "é«˜ä¸€"},
    "subject": "æ•°å­¦",
    "weak_areas": ["å‡½æ•°å®šä¹‰åŸŸ"],
    "target_score": 95
}

result = await tutoring_agent.generate_plan(request)
print(result)
```

### 4. ä½¿ç”¨æ™ºèƒ½ä½“ç®¡ç†å™¨

```python
from service.llm.agents import AgentManager

# åˆ›å»ºæ™ºèƒ½ä½“ç®¡ç†å™¨
agent_manager = AgentManager(llm_client)

# è·å–æ™ºèƒ½ä½“
teaching_agent = agent_manager.get_agent("teaching_analysis")
learning_agent = agent_manager.get_agent("learning_status")
tutoring_agent = agent_manager.get_agent("tutoring_plan")
classroom_agent = agent_manager.get_agent("classroom_ai")

# ä½¿ç”¨æ™ºèƒ½ä½“
result = await teaching_agent.analyze_material(material)
```

## é«˜çº§åŠŸèƒ½

### æ€§èƒ½ä¼˜åŒ–

#### ä½¿ç”¨ç¼“å­˜

```python
from service.llm.optimization import cached

@cached(key="teaching_analysis", ttl=3600)
async def analyze_teaching_material(material):
    # æ•™æåˆ†æé€»è¾‘
    return result
```

#### å¹¶å‘å¤„ç†

```python
from service.llm.optimization import concurrent

@concurrent
async def process_multiple_students(student_list):
    # æ‰¹é‡å¤„ç†å­¦ç”Ÿæ•°æ®
    return results
```

#### æ€§èƒ½ç›‘æ§

```python
from service.llm.optimization import monitored

@monitored
async def generate_tutoring_plan(request):
    # ç”Ÿæˆè¾…å¯¼æ–¹æ¡ˆ
    return plan
```

### ä¸Šä¸‹æ–‡ç®¡ç†

```python
from service.llm.context import ContextManager, SessionManager

# åˆ›å»ºä¼šè¯ç®¡ç†å™¨
session_manager = SessionManager()
context_manager = ContextManager()

# åˆ›å»ºä¼šè¯
session = session_manager.create_session(
    user_id="teacher_001",
    user_role="teacher"
)

# åˆ›å»ºä¸Šä¸‹æ–‡
context_id = context_manager.create_context(
    session_id=session.session_id,
    context_type="teaching_consultation"
)

# æ·»åŠ å¯¹è¯
context_manager.add_message(context_id, "user", "è¯·åˆ†æè¿™é“æ•°å­¦é¢˜")
context_manager.add_message(context_id, "assistant", "å¥½çš„ï¼Œæˆ‘æ¥åˆ†æ...")

# è·å–å¯¹è¯å†å²
history = context_manager.get_conversation_history(context_id)
```

### æç¤ºè¯ç®¡ç†

```python
from service.llm.prompts import PromptManager

# åˆ›å»ºæç¤ºè¯ç®¡ç†å™¨
prompt_manager = PromptManager()

# è·å–æ¨¡æ¿
template = prompt_manager.get_template(
    "teaching_analysis", 
    "analyze_knowledge_points"
)

# æ ¼å¼åŒ–æ¨¡æ¿
formatted_prompt = prompt_manager.format_template(
    "teaching_analysis",
    "analyze_knowledge_points",
    {
        "subject": "æ•°å­¦",
        "content": "å‡½æ•°æ¦‚å¿µ",
        "grade_level": "é«˜ä¸€"
    }
)
```

## é…ç½®è¯´æ˜

### LLMé…ç½®

```python
from service.llm.llm_client import LLMConfig

config = LLMConfig(
    provider="tongyi",           # æä¾›å•†: tongyi, openai
    api_key="your-api-key",     # APIå¯†é’¥
    model="qwen-plus",          # æ¨¡å‹åç§°
    temperature=0.7,            # æ¸©åº¦å‚æ•°
    max_tokens=2000,            # æœ€å¤§tokenæ•°
    timeout=30,                 # è¶…æ—¶æ—¶é—´
    max_retries=3,              # æœ€å¤§é‡è¯•æ¬¡æ•°
    retry_delay=1.0             # é‡è¯•å»¶è¿Ÿ
)
```

### ä¼˜åŒ–é…ç½®

```python
from service.llm.optimization import OptimizationConfig, OptimizationStrategy

config = OptimizationConfig(
    strategy=OptimizationStrategy.BALANCED,  # ä¼˜åŒ–ç­–ç•¥
    enable_cache=True,                       # å¯ç”¨ç¼“å­˜
    cache_ttl=3600,                         # ç¼“å­˜TTL
    enable_concurrent=True,                  # å¯ç”¨å¹¶å‘
    max_workers=4,                          # æœ€å¤§å·¥ä½œçº¿ç¨‹
    enable_monitoring=True,                  # å¯ç”¨ç›‘æ§
    enable_auto_optimization=True           # å¯ç”¨è‡ªåŠ¨ä¼˜åŒ–
)
```

## APIå‚è€ƒ

### æ™ºèƒ½ä½“æ¥å£

#### TeachingAnalysisAgent

```python
class TeachingAnalysisAgent:
    async def analyze_material(self, material: Dict) -> Dict:
        """åˆ†ææ•™æå†…å®¹"""
        pass
    
    async def extract_knowledge_points(self, content: str) -> List[str]:
        """æå–çŸ¥è¯†ç‚¹"""
        pass
    
    async def assess_difficulty(self, content: str, grade: str) -> str:
        """è¯„ä¼°éš¾åº¦"""
        pass
```

#### LearningStatusAgent

```python
class LearningStatusAgent:
    async def analyze_learning_status(self, student_data: Dict) -> Dict:
        """åˆ†æå­¦ä¹ çŠ¶æ€"""
        pass
    
    async def identify_strengths_weaknesses(self, scores: Dict) -> Dict:
        """è¯†åˆ«å¼ºé¡¹å’Œå¼±é¡¹"""
        pass
    
    async def predict_performance(self, historical_data: List) -> Dict:
        """é¢„æµ‹å­¦ä¹ è¡¨ç°"""
        pass
```

#### TutoringPlanAgent

```python
class TutoringPlanAgent:
    async def generate_plan(self, request: Dict) -> Dict:
        """ç”Ÿæˆè¾…å¯¼æ–¹æ¡ˆ"""
        pass
    
    async def recommend_exercises(self, weak_areas: List, level: str) -> List:
        """æ¨èç»ƒä¹ """
        pass
    
    async def create_study_schedule(self, plan: Dict, time_available: str) -> Dict:
        """åˆ›å»ºå­¦ä¹ è®¡åˆ’"""
        pass
```

### ç®¡ç†å™¨æ¥å£

#### AgentManager

```python
class AgentManager:
    def get_agent(self, agent_type: str) -> BaseAgent:
        """è·å–æ™ºèƒ½ä½“"""
        pass
    
    def register_agent(self, agent_type: str, agent: BaseAgent):
        """æ³¨å†Œæ™ºèƒ½ä½“"""
        pass
    
    async def process_request(self, agent_type: str, request: Dict) -> Dict:
        """å¤„ç†è¯·æ±‚"""
        pass
```

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

```python
try:
    result = await teaching_agent.analyze_material(material)
except Exception as e:
    logger.error(f"æ•™æåˆ†æå¤±è´¥: {e}")
    # å¤„ç†é”™è¯¯
```

### 2. èµ„æºç®¡ç†

```python
# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
async with agent_manager:
    result = await agent_manager.process_request("teaching_analysis", request)

# æˆ–æ‰‹åŠ¨æ¸…ç†
try:
    # ä½¿ç”¨æ™ºèƒ½ä½“
    pass
finally:
    agent_manager.cleanup()
```

### 3. æ€§èƒ½ä¼˜åŒ–

```python
# ä½¿ç”¨è£…é¥°å™¨ç»„åˆ
@cached(key="analysis", ttl=1800)
@monitored
@concurrent
async def comprehensive_analysis(data):
    # ç»¼åˆåˆ†æé€»è¾‘
    return result
```

### 4. é…ç½®ç®¡ç†

```python
# ä½¿ç”¨ç¯å¢ƒå˜é‡
import os

config = LLMConfig(
    provider=os.getenv("LLM_PROVIDER", "tongyi"),
    api_key=os.getenv("LLM_API_KEY"),
    model=os.getenv("LLM_MODEL", "qwen-plus")
)
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **APIå¯†é’¥é”™è¯¯**
   - æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®
   - ç¡®è®¤APIå¯†é’¥æƒé™

2. **ç½‘ç»œè¿æ¥é—®é¢˜**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - é…ç½®ä»£ç†è®¾ç½®

3. **å†…å­˜ä½¿ç”¨è¿‡é«˜**
   - å¯ç”¨ç¼“å­˜æ¸…ç†
   - è°ƒæ•´ç¼“å­˜å¤§å°
   - ä½¿ç”¨å†…å­˜ä¼˜åŒ–ç­–ç•¥

4. **å“åº”æ—¶é—´è¿‡é•¿**
   - å¯ç”¨ç¼“å­˜
   - ä½¿ç”¨å¹¶å‘å¤„ç†
   - ä¼˜åŒ–æç¤ºè¯é•¿åº¦

### è°ƒè¯•æŠ€å·§

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# ä½¿ç”¨æ€§èƒ½ç›‘æ§
from service.llm.optimization import get_global_monitor
monitor = get_global_monitor()
stats = monitor.get_system_stats()
print(f"ç³»ç»ŸçŠ¶æ€: {stats}")

# æ£€æŸ¥ç¼“å­˜çŠ¶æ€
cache_manager = optimization_manager.get_cache_manager()
if cache_manager:
    cache_stats = cache_manager.get_stats()
    print(f"ç¼“å­˜ç»Ÿè®¡: {cache_stats}")
```

## è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. æ¨é€åˆ°åˆ†æ”¯
5. åˆ›å»º Pull Request

## è®¸å¯è¯

MIT License

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»å¼€å‘å›¢é˜Ÿã€‚

---

**æ³¨æ„**: ä½¿ç”¨å‰è¯·ç¡®ä¿å·²æ­£ç¡®é…ç½®ç›¸åº”çš„APIå¯†é’¥å’Œç½‘ç»œç¯å¢ƒã€‚